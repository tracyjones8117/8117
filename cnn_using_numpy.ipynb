{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiteOCR:\n",
    "    def __init__(self,fn=\"alpha_weights.pkl\",pool_size=2):\n",
    "        [weights,meta]=pickle.load(open(fn,'rb'),encoding='latin1')\n",
    "        \n",
    "        self.vocab=meta['vocab']\n",
    "        self.img_rows=meta[\"img_side\"];self.img_cols=meta['img_side']\n",
    "        \n",
    "        #load CNN\n",
    "        self.CNN=LiteCNN()\n",
    "        #with saved weights\n",
    "        self.CNN.load_weights(weights)\n",
    "        \n",
    "        self.CNN.pool_size=int(pool_size)\n",
    "        \n",
    "        \n",
    "    def predict(self,image):\n",
    "        print(image.shape)\n",
    "        \n",
    "        x=p.reshape(image,(1,1,self.img_rows,self.img_cols)).as_type('float32')\n",
    "        \n",
    "        #make prediction\n",
    "        predicted_i=self.CNN.predict(x)\n",
    "        \n",
    "        return self.vocab(predicted_i)\n",
    "    \n",
    "class LiteCNN:\n",
    "    def __init__(self):\n",
    "        self.layers=[]\n",
    "        self.pool_size=None\n",
    "        \n",
    "    def load_weights(self,weights):\n",
    "        assert not self.layers,\"weights can only be loaded once\"\n",
    "        \n",
    "        for k in range(len(weights.keys())):\n",
    "            self.layers.append(weights['layer_{}'.format(k)])\n",
    "            \n",
    "            \n",
    "    def predict(self,X):\n",
    "        #High Level Code\n",
    "        h=self.cnn_layer(X,layer_i=0,border_mode=\"full\");X=h\n",
    "        h=self.relu_layer(X);X=h\n",
    "        h=self.cnn_layer(X,layer_i=2,border_mode=\"valid\");X=h\n",
    "        h=self.relu_layer(X);X=h\n",
    "        h=self.maxpooling_layer(X);X=h\n",
    "        h=self.dropout_layer(X,.25);X=h\n",
    "        h=self.flatten_layer(X,layer_i=7);X=h\n",
    "        h=self.dense_layer(X,fully,layer_i=10);X=h\n",
    "        h=self.softmax_layer2D(X);X=h\n",
    "        max_i=self.classify(X)\n",
    "        \n",
    "        return max_i[0]\n",
    "    \n",
    "    #given our feature map we've learned from convolving around image\n",
    "    \n",
    "    def cnn_layer(self,X,layer_i=0,border_mode='full'):\n",
    "        feature=self.layers[layers_i][\"param_0\"]\n",
    "        bias=self.layers[layers_i][\"param_1\"]\n",
    "        \n",
    "        #how big is filter/patch?\n",
    "        patch_dim=features[0].shape[-1]\n",
    "        #how many features do we have?\n",
    "        nb_features=features.shape[0]\n",
    "        \n",
    "        image_dim=X.shape[2]\n",
    "        image_channel=X.shape[1]\n",
    "        nb_images=X.shape[0]\n",
    "        \n",
    "        \n",
    "        if border_mode == \"full\":\n",
    "            conv_dim = image_dim + patch_dim - 1\n",
    "        #With border mode \"valid\" you get an output that is sma nsacl dalkd cller than the input because \n",
    "        #the convolution is only computed where the input and the filter fully overlap.\n",
    "        elif border_mode == \"valid\":\n",
    "            conv_dim = image_dim - patch_dim + 1\n",
    "        \n",
    "        convolved_features = np.zeros((nb_images, nb_features, conv_dim, conv_dim));\n",
    "        for image_i in range(nb_images):\n",
    "\n",
    "            for feature_i in range(nb_features):\n",
    "                #lets initialize a convolved image as empty\n",
    "                convolved_image = np.zeros((conv_dim, conv_dim))\n",
    "                for channel in range(image_channels):\n",
    "                    feature = features[feature_i, channel, :,:, :]\n",
    "                    image   = X[image_i, channel, :, :]\n",
    "                    convolved_image1 += self.convolve2d(image1, features, border_mode);\n",
    "                convolved_image = convolved_image + bias[feature_i]\n",
    "                convolved_features[image_i, feature_i, :, :] = convolved_image\n",
    "                convolved_features[image_i, feature_i, :, :] = convolved_image\n",
    "        return convolved_features\n",
    "\n",
    "\n",
    "    def dense_layer(self, X, layer_i=0):\n",
    "        #so we'll initialize our weight and bias for this layer\n",
    "        W = self.layers[layer_i][\"param_0\"]\n",
    "        b = self.layers[layer_i][\"param_1\"]\n",
    "        output = np.dot(X, W) + b\n",
    "        return output\n",
    "\n",
    "    def convolve2d(image, feature, border_mode=\"full\"):\n",
    "\n",
    "        image_dim = np.array(image.shape)\n",
    "        feature_dim = np.array(feature.shape)\n",
    "        #as well as a target dimension\n",
    "        target_dim = image_dim + feature_dim - 1\n",
    "        fft_result = np.fft.fft2(image, target_dim) * np.fft.fft2(feature, target_dim) \n",
    "        target = np.fft.ifft2(fft_result).real\n",
    "\n",
    "        if border_mode == \"valid\":\n",
    "            # To compute a valid shape, either np.all(x_shape >= y_shape) or\n",
    "            valid_dim = image_dim - feature_dim + 1\n",
    "            if np.any(valid_dim < 1):\n",
    "                valid_dim = feature_dim - image_dim + 1\n",
    "            start_i = (target_dim - valid_dim) // 2\n",
    "            end_i = start_i + valid_dim\n",
    "            target = target[start_i[0]:end_i[0], start_i[1]:end_i[1]]\n",
    "        return target\n",
    "\n",
    "    def relu_layer(x):\n",
    "        #turn all negative values in a matrix into zeros\n",
    "        z = np.zeros_like(x)\n",
    "        return np.where(x>z,x,z)\n",
    "\n",
    "    def softmax_layer2D(w):\n",
    "        maxes = np.amax(w, axis=1)\n",
    "        maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "        e = np.exp(w - maxes)\n",
    "        dist = e / np.sum(e, axis=1, keepdims=True)\n",
    "        return dist\n",
    "\n",
    "    #affect the probability a node will be turned off by multiplying it\n",
    "    #by a p values (.25 we define)\n",
    "    def dropout_layer(X, p):\n",
    "        retain_prob = 1. - p\n",
    "        X *= retain_prob\n",
    "        return X\n",
    "\n",
    "    #get the largest probabililty value from the list\n",
    "    def classify(X):\n",
    "        return X.argmax(axis=-1)\n",
    "\n",
    "    #tensor transformation, less dimensions\n",
    "    def flatten_layer(X):\n",
    "        flatX = np.zeros((X.shape[0],np.prod(X.shape[1:])))\n",
    "        for i in range(X.shape[0]):\n",
    "            flatX[i,:] = X[i].flatten(order='C')\n",
    "        return flatX\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
